{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ultralytics\n",
    "ultralytics.checks()\n",
    "# !yolo task=detect mode=train model=weights/yolo/yolov8s.pt data={file_path} epochs=50 imgsz=640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def rewritePath(path):\n",
    "    return path.replace(\"\\\\\", \"/\")\n",
    "\n",
    "print(os.getcwd())\n",
    "data_path = rewritePath(os.getcwd() + \"/datasets/pringles/data.yaml\")\n",
    "yolo_path = rewritePath(os.getcwd() + \"/weights/yolo/yolov8s.pt\")\n",
    "\n",
    "# print(data_path, yolo_path, os.path.exists(data_path), os.path.exists(yolo_path))\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(yolo_path)\n",
    "results = model.train(data = data_path, epochs = 50, imgsz = 640)\n",
    "results = results.val()\n",
    "\n",
    "# model.export(format=\"pytorch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 a pringles, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.07958984375, 0.0, 639.556396484375, 478.9527587890625]] [0.9582688808441162] [0.0]\n",
      "Class: a pringles, Confidence: 0.9582688808441162, Bounding Box: (0.07958984375, 0.0, 639.556396484375, 478.9527587890625)\n"
     ]
    }
   ],
   "source": [
    "import ultralytics\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.utils import yaml_load\n",
    "from ultralytics.utils.checks import check_yaml\n",
    "\n",
    "model = YOLO('weights\\weights-train1\\last.pt')\n",
    "classes = yaml_load(check_yaml('datasets\\pringles\\data.yaml'))['names']\n",
    "colors = np.random.uniform(0, 255, size=(len(classes), 3))\n",
    "\n",
    "# Load the example image\n",
    "image_path = 'datasets\\\\rgbd_dataset\\\\rgb_8.png'\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Perform object detection\n",
    "results = model(image)\n",
    "\n",
    "plots = results[0].plot()\n",
    "boxes = results[0].boxes\n",
    "# Get the bounding box attributes\n",
    "xyxy = boxes[0].xyxy.tolist()\n",
    "confidences = boxes[0].conf.tolist()\n",
    "class_ids = boxes[0].cls.tolist()\n",
    "\n",
    "print(xyxy, confidences, class_ids)\n",
    "# Print the bounding box attributes\n",
    "for box, confidence, class_id in zip(xyxy, confidences, class_ids):\n",
    "    x1, y1, x2, y2 = box\n",
    "    class_name = classes[int(class_id)]\n",
    "    print(f\"Class: {class_name}, Confidence: {confidence}, Bounding Box: ({x1}, {y1}, {x2}, {y2})\")\n",
    "\n",
    "# Display the result with PIL\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
