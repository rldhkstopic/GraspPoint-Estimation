{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.169  Python-3.10.9 torch-2.1.1+cu121 CUDA:0 (NVIDIA GeForce RTX 2070 SUPER, 8192MiB)\n",
      "Setup complete  (8 CPUs, 31.9 GB RAM, 199.2/237.9 GB disk)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'roboflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 7\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# !yolo task=detect mode=train model=weights/yolo/yolov8s.pt data={file_path} epochs=50 imgsz=640\u001b[39;00m\n\u001b[0;32m      5\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconda install roboflow\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mroboflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Roboflow\n\u001b[0;32m      8\u001b[0m rf \u001b[38;5;241m=\u001b[39m Roboflow(api_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt8tlmLYQm0nPrAZSB7Qd\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      9\u001b[0m project \u001b[38;5;241m=\u001b[39m rf\u001b[38;5;241m.\u001b[39mworkspace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhanyang-2zmez\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mproject(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpringles-miuc6\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'roboflow'"
     ]
    }
   ],
   "source": [
    "import ultralytics\n",
    "ultralytics.checks()\n",
    "# !yolo task=detect mode=train model=weights/yolo/yolov8s.pt data={file_path} epochs=50 imgsz=640\n",
    "\n",
    "!conda install roboflow\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"t8tlmLYQm0nPrAZSB7Qd\")\n",
    "project = rf.workspace(\"hanyang-2zmez\").project(\"pringles-miuc6\")\n",
    "dataset = project.version(8).download(\"yolov8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.0.227 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.169  Python-3.10.9 torch-2.1.1+cu121 CUDA:0 (NVIDIA GeForce RTX 2070 SUPER, 8192MiB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rldhkstopic\\Desktop\\VisualCode\\GraspPoint-Estimation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=c:/Users/rldhkstopic/Desktop/VisualCode/GraspPoint-Estimation/weights/yolo/yolov8s.pt, data=c:/Users/rldhkstopic/Desktop/VisualCode/GraspPoint-Estimation/datasets/pringles/data.yaml, epochs=50, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train6\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Dataset 'c://Users/rldhkstopic/Desktop/VisualCode/GraspPoint-Estimation/datasets/pringles/data.yaml' error  'c:/Users/rldhkstopic/Desktop/VisualCode/GraspPoint-Estimation/datasets/pringles/data.yaml' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\rldhkstopic\\anaconda3\\lib\\site-packages\\ultralytics\\engine\\trainer.py:118\u001b[0m, in \u001b[0;36mBaseTrainer.__init__\u001b[1;34m(self, cfg, overrides, _callbacks)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myaml\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124myml\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtask \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdetect\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msegment\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpose\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m--> 118\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_det_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124myaml_file\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata:\n",
      "File \u001b[1;32mc:\\Users\\rldhkstopic\\anaconda3\\lib\\site-packages\\ultralytics\\data\\utils.py:242\u001b[0m, in \u001b[0;36mcheck_det_dataset\u001b[1;34m(dataset, autodownload)\u001b[0m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;124;03mDownload, verify, and/or unzip a dataset if not found locally.\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;124;03m    (dict): Parsed dataset information and paths.\u001b[39;00m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 242\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;66;03m# Download (optional)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\rldhkstopic\\anaconda3\\lib\\site-packages\\ultralytics\\utils\\checks.py:378\u001b[0m, in \u001b[0;36mcheck_file\u001b[1;34m(file, suffix, download, hard)\u001b[0m\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m files \u001b[38;5;129;01mand\u001b[39;00m hard:\n\u001b[1;32m--> 378\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m does not exist\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(files) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m hard:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: 'c:/Users/rldhkstopic/Desktop/VisualCode/GraspPoint-Estimation/datasets/pringles/data.yaml' does not exist",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m YOLO\n\u001b[0;32m     14\u001b[0m model \u001b[38;5;241m=\u001b[39m YOLO(yolo_path)\n\u001b[1;32m---> 15\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m640\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rldhkstopic\\anaconda3\\lib\\site-packages\\ultralytics\\engine\\model.py:336\u001b[0m, in \u001b[0;36mModel.train\u001b[1;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresume\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    334\u001b[0m     args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresume\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mckpt_path\n\u001b[1;32m--> 336\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msmart_load\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrainer\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43moverrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_callbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresume\u001b[39m\u001b[38;5;124m'\u001b[39m):  \u001b[38;5;66;03m# manually set model only if not resuming\u001b[39;00m\n\u001b[0;32m    338\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mget_model(weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mckpt \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, cfg\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39myaml)\n",
      "File \u001b[1;32mc:\\Users\\rldhkstopic\\anaconda3\\lib\\site-packages\\ultralytics\\engine\\trainer.py:122\u001b[0m, in \u001b[0;36mBaseTrainer.__init__\u001b[1;34m(self, cfg, overrides, _callbacks)\u001b[0m\n\u001b[0;32m    120\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myaml_file\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# for validating 'yolo train data=url.zip' usage\u001b[39;00m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(emojis(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclean_url(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdata)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m error ❌ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainset, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtestset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_dataset(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata)\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Dataset 'c://Users/rldhkstopic/Desktop/VisualCode/GraspPoint-Estimation/datasets/pringles/data.yaml' error  'c:/Users/rldhkstopic/Desktop/VisualCode/GraspPoint-Estimation/datasets/pringles/data.yaml' does not exist"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def rewritePath(path):\n",
    "    return path.replace(\"\\\\\", \"/\")\n",
    "\n",
    "print(os.getcwd())\n",
    "data_path = rewritePath(os.getcwd() + \"/datasets/pringles/data.yaml\")\n",
    "yolo_path = rewritePath(os.getcwd() + \"/weights/yolo/yolov8s.pt\")\n",
    "\n",
    "# print(data_path, yolo_path, os.path.exists(data_path), os.path.exists(yolo_path))\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(yolo_path)\n",
    "results = model.train(data = data_path, epochs = 50, imgsz = 640)\n",
    "\n",
    "# model.export(format=\"pytorch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 a pringles, 56.0ms\n",
      "Speed: 3.0ms preprocess, 56.0ms inference, 104.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: a pringles, Confidence: 0.8771205544471741, Bounding Box: (241.56475830078125, 210.70956420898438, 548.71728515625, 312.4115295410156)\n",
      "Class: a pringles, Confidence: 0.8771205544471741, Bounding Box: (241.56475830078125, 210.70956420898438, 548.71728515625, 312.4115295410156)\n"
     ]
    }
   ],
   "source": [
    "import ultralytics\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.utils import yaml_load\n",
    "from ultralytics.utils.checks import check_yaml\n",
    "\n",
    "model = YOLO('weights\\weights5\\last.pt')\n",
    "classes = yaml_load(check_yaml('datasets\\pringles-8\\data.yaml'))['names']\n",
    "colors = np.random.uniform(0, 255, size=(len(classes), 3))\n",
    "\n",
    "# Load the example image\n",
    "image_path = 'datasets\\\\rgbd_dataset\\\\rgb_8.png'\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "results = model(image)\n",
    "plots = results[0].plot()\n",
    "\n",
    "for result in results:\n",
    "    boxes = result.boxes\n",
    "    for box in boxes:\n",
    "        xyxy = box.xyxy.tolist()\n",
    "        confidences = box.conf.tolist()\n",
    "        class_ids = box.cls.tolist()\n",
    "        for box, confidence, class_id in zip(xyxy, confidences, class_ids):\n",
    "            x1, y1, x2, y2 = box\n",
    "            class_name = classes[int(class_id)]\n",
    "            print(f\"Class: {class_name}, Confidence: {confidence}, Bounding Box: ({x1}, {y1}, {x2}, {y2})\")\n",
    "\n",
    "for box, confidence, class_id in zip(xyxy, confidences, class_ids):\n",
    "    x1, y1, x2, y2 = box\n",
    "    class_name = classes[int(class_id)]\n",
    "    print(f\"Class: {class_name}, Confidence: {confidence}, Bounding Box: ({x1}, {y1}, {x2}, {y2})\")\n",
    "\n",
    "# Display the result with PIL\n",
    "image = Image.fromarray(plots)\n",
    "image.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 c:\\Users\\rldhkstopic\\Desktop\\VisualCode\\GraspPoint-Estimation\\datasets\\rgbd_dataset\\rgb_1.png: 480x640 1 a pringles, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict2\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'a pringles'}\n",
       " orig_img: array([[[ 80,  78,  95],\n",
       "         [ 80,  78,  95],\n",
       "         [ 79,  79,  96],\n",
       "         ...,\n",
       "         [ 68,  63,  67],\n",
       "         [ 73,  64,  71],\n",
       "         [ 70,  61,  68]],\n",
       " \n",
       "        [[ 79,  78,  93],\n",
       "         [ 80,  79,  94],\n",
       "         [ 79,  80,  95],\n",
       "         ...,\n",
       "         [ 67,  64,  68],\n",
       "         [ 70,  66,  72],\n",
       "         [ 67,  63,  69]],\n",
       " \n",
       "        [[ 77,  78,  93],\n",
       "         [ 78,  79,  94],\n",
       "         [ 79,  81,  93],\n",
       "         ...,\n",
       "         [ 69,  67,  68],\n",
       "         [ 70,  67,  71],\n",
       "         [ 69,  66,  70]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 49,  59,  74],\n",
       "         [ 53,  63,  78],\n",
       "         [ 49,  60,  73],\n",
       "         ...,\n",
       "         [ 89,  94, 105],\n",
       "         [ 86,  93, 104],\n",
       "         [ 86,  93, 104]],\n",
       " \n",
       "        [[ 49,  61,  76],\n",
       "         [ 51,  63,  78],\n",
       "         [ 49,  60,  73],\n",
       "         ...,\n",
       "         [ 88,  93, 104],\n",
       "         [ 90,  95, 106],\n",
       "         [ 88,  93, 104]],\n",
       " \n",
       "        [[ 49,  62,  75],\n",
       "         [ 51,  64,  77],\n",
       "         [ 46,  59,  72],\n",
       "         ...,\n",
       "         [ 89,  91, 103],\n",
       "         [ 91,  96, 107],\n",
       "         [ 90,  95, 106]]], dtype=uint8)\n",
       " orig_shape: (480, 640)\n",
       " path: 'c:\\\\Users\\\\rldhkstopic\\\\Desktop\\\\VisualCode\\\\GraspPoint-Estimation\\\\datasets\\\\rgbd_dataset\\\\rgb_1.png'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict2'\n",
       " speed: {'preprocess': 1.0018348693847656, 'inference': 8.996725082397461, 'postprocess': 2.0012855529785156}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgbd_path = os.getcwd() + '/datasets/rgbd_dataset/'\n",
    "\n",
    "num = 1\n",
    "rgb = rgbd_path + f'rgb_{num}.png'\n",
    "depth = rgbd_path + f'depth_{num}.png'\n",
    "run_path = rewritePath(os.getcwd() + \"/weights/weights5/last.pt\")\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(run_path)\n",
    "model.predict(\n",
    "    source=rgb,\n",
    "    conf=0.25,\n",
    "    save=True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
